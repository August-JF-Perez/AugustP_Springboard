{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj",
    "tags": []
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>120932.8881</td>\n",
       "      <td>69158.16225</td>\n",
       "      <td>79885.89069</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.48001</td>\n",
       "      <td>44803.42878</td>\n",
       "      <td>45544.52227</td>\n",
       "      <td>48527.52339</td>\n",
       "      <td>56701.5961</td>\n",
       "      <td>74435.76052</td>\n",
       "      <td>64018.87894</td>\n",
       "      <td>54705.1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>119508.8622</td>\n",
       "      <td>68951.09542</td>\n",
       "      <td>80897.06551</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.42289</td>\n",
       "      <td>44528.80721</td>\n",
       "      <td>46051.57066</td>\n",
       "      <td>49341.29029</td>\n",
       "      <td>56593.59475</td>\n",
       "      <td>72777.93709</td>\n",
       "      <td>63715.02399</td>\n",
       "      <td>54356.14843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>120282.2131</td>\n",
       "      <td>68712.44341</td>\n",
       "      <td>81379.86288</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.8681</td>\n",
       "      <td>45200.46775</td>\n",
       "      <td>45383.82395</td>\n",
       "      <td>49442.17973</td>\n",
       "      <td>56171.18278</td>\n",
       "      <td>73896.84204</td>\n",
       "      <td>64113.60858</td>\n",
       "      <td>53583.07667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>120097.899</td>\n",
       "      <td>68610.04641</td>\n",
       "      <td>82188.90498</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.7796</td>\n",
       "      <td>45614.34341</td>\n",
       "      <td>46124.23045</td>\n",
       "      <td>49455.93299</td>\n",
       "      <td>56567.89582</td>\n",
       "      <td>74455.28754</td>\n",
       "      <td>64623.22395</td>\n",
       "      <td>54786.01938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.8548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 City of London Barking & Dagenham       Barnet       Bexley  \\\n",
       "0        NaT      E09000001          E09000002    E09000003    E09000004   \n",
       "1 1995-01-01    91448.98487         50460.2266  93284.51832  64958.09036   \n",
       "2 1995-02-01    82202.77314        51085.77983  93190.16963  64787.92069   \n",
       "3 1995-03-01    79120.70256        51268.96956  92247.52435  64367.49344   \n",
       "4 1995-04-01    77101.20804        53133.50526  90762.87492  64277.66881   \n",
       "\n",
       "         Brent      Bromley       Camden      Croydon       Ealing  ...  \\\n",
       "0    E09000005    E09000006    E09000007    E09000008    E09000009  ...   \n",
       "1  71306.56698  81671.47692  120932.8881  69158.16225  79885.89069  ...   \n",
       "2  72022.26197  81657.55944  119508.8622  68951.09542  80897.06551  ...   \n",
       "3  72015.76274  81449.31143  120282.2131  68712.44341  81379.86288  ...   \n",
       "4  72965.63094  81124.41227   120097.899  68610.04641  82188.90498  ...   \n",
       "\n",
       "    NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND  \\\n",
       "0    E12000002          E12000003     E12000004     E12000005       E12000006   \n",
       "1  43958.48001        44803.42878   45544.52227   48527.52339      56701.5961   \n",
       "2  43925.42289        44528.80721   46051.57066   49341.29029     56593.59475   \n",
       "3   44434.8681        45200.46775   45383.82395   49442.17973     56171.18278   \n",
       "4   44267.7796        45614.34341   46124.23045   49455.93299     56567.89582   \n",
       "\n",
       "        LONDON   SOUTH EAST   SOUTH WEST Unnamed: 47      England  \n",
       "0    E12000007    E12000008    E12000009         NaN    E92000001  \n",
       "1  74435.76052  64018.87894   54705.1579         NaN  53202.77128  \n",
       "2  72777.93709  63715.02399  54356.14843         NaN   53096.1549  \n",
       "3  73896.84204  64113.60858  53583.07667         NaN   53201.2843  \n",
       "4  74455.28754  64623.22395  54786.01938         NaN   53590.8548  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape: \n",
      "(rows,cols)\n",
      "(346, 49)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "info: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346 entries, 0 to 345\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            345 non-null    datetime64[ns]\n",
      " 1   City of London        346 non-null    object        \n",
      " 2   Barking & Dagenham    346 non-null    object        \n",
      " 3   Barnet                346 non-null    object        \n",
      " 4   Bexley                346 non-null    object        \n",
      " 5   Brent                 346 non-null    object        \n",
      " 6   Bromley               346 non-null    object        \n",
      " 7   Camden                346 non-null    object        \n",
      " 8   Croydon               346 non-null    object        \n",
      " 9   Ealing                346 non-null    object        \n",
      " 10  Enfield               346 non-null    object        \n",
      " 11  Greenwich             346 non-null    object        \n",
      " 12  Hackney               346 non-null    object        \n",
      " 13  Hammersmith & Fulham  346 non-null    object        \n",
      " 14  Haringey              346 non-null    object        \n",
      " 15  Harrow                346 non-null    object        \n",
      " 16  Havering              346 non-null    object        \n",
      " 17  Hillingdon            346 non-null    object        \n",
      " 18  Hounslow              346 non-null    object        \n",
      " 19  Islington             346 non-null    object        \n",
      " 20  Kensington & Chelsea  346 non-null    object        \n",
      " 21  Kingston upon Thames  346 non-null    object        \n",
      " 22  Lambeth               346 non-null    object        \n",
      " 23  Lewisham              346 non-null    object        \n",
      " 24  Merton                346 non-null    object        \n",
      " 25  Newham                346 non-null    object        \n",
      " 26  Redbridge             346 non-null    object        \n",
      " 27  Richmond upon Thames  346 non-null    object        \n",
      " 28  Southwark             346 non-null    object        \n",
      " 29  Sutton                346 non-null    object        \n",
      " 30  Tower Hamlets         346 non-null    object        \n",
      " 31  Waltham Forest        346 non-null    object        \n",
      " 32  Wandsworth            346 non-null    object        \n",
      " 33  Westminster           346 non-null    object        \n",
      " 34  Unnamed: 34           0 non-null      float64       \n",
      " 35  Inner London          346 non-null    object        \n",
      " 36  Outer London          346 non-null    object        \n",
      " 37  Unnamed: 37           0 non-null      float64       \n",
      " 38  NORTH EAST            346 non-null    object        \n",
      " 39  NORTH WEST            346 non-null    object        \n",
      " 40  YORKS & THE HUMBER    346 non-null    object        \n",
      " 41  EAST MIDLANDS         346 non-null    object        \n",
      " 42  WEST MIDLANDS         346 non-null    object        \n",
      " 43  EAST OF ENGLAND       346 non-null    object        \n",
      " 44  LONDON                346 non-null    object        \n",
      " 45  SOUTH EAST            346 non-null    object        \n",
      " 46  SOUTH WEST            346 non-null    object        \n",
      " 47  Unnamed: 47           0 non-null      float64       \n",
      " 48  England               346 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(45)\n",
      "memory usage: 132.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\nshape: \\n(rows,cols)')\n",
    "print(properties.shape)\n",
    "print(('-'*100),'\\ninfo: \\n')\n",
    "print(properties.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2009-05-01 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002-03-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2009-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-09-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0  Unnamed: 34  Unnamed: 37  Unnamed: 47\n",
       "count                  345          0.0          0.0          0.0\n",
       "mean   2009-05-01 16:00:00          NaN          NaN          NaN\n",
       "min    1995-01-01 00:00:00          NaN          NaN          NaN\n",
       "25%    2002-03-01 00:00:00          NaN          NaN          NaN\n",
       "50%    2009-05-01 00:00:00          NaN          NaN          NaN\n",
       "75%    2016-07-01 00:00:00          NaN          NaN          NaN\n",
       "max    2023-09-01 00:00:00          NaN          NaN          NaN\n",
       "std                    NaN          NaN          NaN          NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.describe()\n",
    "#AP: useless for now, maybe helpful after data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed shape:\n",
      " (49, 347)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-12-01 00:00:00</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>2023-04-01 00:00:00</td>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>2023-06-01 00:00:00</td>\n",
       "      <td>2023-07-01 00:00:00</td>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>2023-09-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>...</td>\n",
       "      <td>975240</td>\n",
       "      <td>963094</td>\n",
       "      <td>869039</td>\n",
       "      <td>930986</td>\n",
       "      <td>903718</td>\n",
       "      <td>958418</td>\n",
       "      <td>951649</td>\n",
       "      <td>931176</td>\n",
       "      <td>861107</td>\n",
       "      <td>807475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index          0                    1                    2  \\\n",
       "0      Unnamed: 0        NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "1  City of London  E09000001          91448.98487          82202.77314   \n",
       "\n",
       "                     3                    4                    5  \\\n",
       "0  1995-03-01 00:00:00  1995-04-01 00:00:00  1995-05-01 00:00:00   \n",
       "1          79120.70256          77101.20804          84409.14932   \n",
       "\n",
       "                     6                    7                    8  ...  \\\n",
       "0  1995-06-01 00:00:00  1995-07-01 00:00:00  1995-08-01 00:00:00  ...   \n",
       "1          94900.51244          110128.0423          112329.4376  ...   \n",
       "\n",
       "                   336                  337                  338  \\\n",
       "0  2022-12-01 00:00:00  2023-01-01 00:00:00  2023-02-01 00:00:00   \n",
       "1               975240               963094               869039   \n",
       "\n",
       "                   339                  340                  341  \\\n",
       "0  2023-03-01 00:00:00  2023-04-01 00:00:00  2023-05-01 00:00:00   \n",
       "1               930986               903718               958418   \n",
       "\n",
       "                   342                  343                  344  \\\n",
       "0  2023-06-01 00:00:00  2023-07-01 00:00:00  2023-08-01 00:00:00   \n",
       "1               951649               931176               861107   \n",
       "\n",
       "                   345  \n",
       "0  2023-09-01 00:00:00  \n",
       "1               807475  \n",
       "\n",
       "[2 rows x 347 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP: Transpose the properties DF so each borough is a row & reset the index to zero-indexing (originally first col 'index' was set as the index)\n",
    "#AP: chained multiple methods to condense the code a little.\n",
    "properties_2_2 = properties.T.reset_index()\n",
    "print('Transposed shape:\\n', properties_2_2.shape)\n",
    "properties_2_2.head(2) #AP: Three cols b/c 4+ cols output overflows and just easier for me to read/understand w/out overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: skip - properties.info gives me enough info to know I only need to worry about the NaT in second col of properties.T, No other null values besides the entire unnamed rows.\n",
    "#AP: Check how many null values are in row 0 (the row to be set as col names & dropped). Known \"NaT\" at location [1, 0]. If more than 1 null value, need to find location & determine next steps\n",
    "\n",
    "#properties_2_2.columns = range(properties_2_2.columns.size)\n",
    "#print(properties_2_2.columns)\n",
    "#list_of_col_names = list(properties_2_2.iloc[0]) #So I can check if there's any funky col names\n",
    "#cnt_missing = properties_2_2.isnull().sum()\n",
    "#print('-'*100)\n",
    "#print(cnt_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: skip - attempt at getting exact location of nulls\n",
    "#nulls = properties_2_2.isna().values.any(axis=1)\n",
    "#print(properties_2_2.loc[properties_2_2.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: commented this code out. Figured out how to change col name when original is NaT (pd.NaT). This might be good as a reminder to future me of possible alt way of doing it.\n",
    "#AP: Set values in row 0 for first & second col's so don't have to fix later\n",
    "#properties_2_2.iat[0,0] = 'Areas'\n",
    "#properties_2_2.iat[0,1] = 'GSS_Code'\n",
    "#properties_2_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-12-01 00:00:00</th>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <th>2023-02-01 00:00:00</th>\n",
       "      <th>2023-03-01 00:00:00</th>\n",
       "      <th>2023-04-01 00:00:00</th>\n",
       "      <th>2023-05-01 00:00:00</th>\n",
       "      <th>2023-06-01 00:00:00</th>\n",
       "      <th>2023-07-01 00:00:00</th>\n",
       "      <th>2023-08-01 00:00:00</th>\n",
       "      <th>2023-09-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>...</td>\n",
       "      <td>975240</td>\n",
       "      <td>963094</td>\n",
       "      <td>869039</td>\n",
       "      <td>930986</td>\n",
       "      <td>903718</td>\n",
       "      <td>958418</td>\n",
       "      <td>951649</td>\n",
       "      <td>931176</td>\n",
       "      <td>861107</td>\n",
       "      <td>807475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>...</td>\n",
       "      <td>355596</td>\n",
       "      <td>353429</td>\n",
       "      <td>346193</td>\n",
       "      <td>345288</td>\n",
       "      <td>348254</td>\n",
       "      <td>349590</td>\n",
       "      <td>346099</td>\n",
       "      <td>343430</td>\n",
       "      <td>344171</td>\n",
       "      <td>345614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0          Unnamed: 0        NaT 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "1      City of London  E09000001         91448.98487         82202.77314   \n",
       "2  Barking & Dagenham  E09000002          50460.2266         51085.77983   \n",
       "\n",
       "0 1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "1         79120.70256         77101.20804         84409.14932   \n",
       "2         51268.96956         53133.50526         53042.24852   \n",
       "\n",
       "0 1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  ...  \\\n",
       "1         94900.51244         110128.0423         112329.4376  ...   \n",
       "2         53700.34831         52113.12157         52232.19868  ...   \n",
       "\n",
       "0 2022-12-01 00:00:00 2023-01-01 00:00:00 2023-02-01 00:00:00  \\\n",
       "1              975240              963094              869039   \n",
       "2              355596              353429              346193   \n",
       "\n",
       "0 2023-03-01 00:00:00 2023-04-01 00:00:00 2023-05-01 00:00:00  \\\n",
       "1              930986              903718              958418   \n",
       "2              345288              348254              349590   \n",
       "\n",
       "0 2023-06-01 00:00:00 2023-07-01 00:00:00 2023-08-01 00:00:00  \\\n",
       "1              951649              931176              861107   \n",
       "2              346099              343430              344171   \n",
       "\n",
       "0 2023-09-01 00:00:00  \n",
       "1              807475  \n",
       "2              345614  \n",
       "\n",
       "[2 rows x 347 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP: set first row as column names (looks like the dates avg prices reported) & drop row 0 since it's the col names now.\n",
    "properties_2_2.columns = properties_2_2.iloc[0]\n",
    "properties_2_2 = properties_2_2.drop(0)\n",
    "properties_2_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>gss_code</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-12-01 00:00:00</th>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <th>2023-02-01 00:00:00</th>\n",
       "      <th>2023-03-01 00:00:00</th>\n",
       "      <th>2023-04-01 00:00:00</th>\n",
       "      <th>2023-05-01 00:00:00</th>\n",
       "      <th>2023-06-01 00:00:00</th>\n",
       "      <th>2023-07-01 00:00:00</th>\n",
       "      <th>2023-08-01 00:00:00</th>\n",
       "      <th>2023-09-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>...</td>\n",
       "      <td>975240</td>\n",
       "      <td>963094</td>\n",
       "      <td>869039</td>\n",
       "      <td>930986</td>\n",
       "      <td>903718</td>\n",
       "      <td>958418</td>\n",
       "      <td>951649</td>\n",
       "      <td>931176</td>\n",
       "      <td>861107</td>\n",
       "      <td>807475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>...</td>\n",
       "      <td>355596</td>\n",
       "      <td>353429</td>\n",
       "      <td>346193</td>\n",
       "      <td>345288</td>\n",
       "      <td>348254</td>\n",
       "      <td>349590</td>\n",
       "      <td>346099</td>\n",
       "      <td>343430</td>\n",
       "      <td>344171</td>\n",
       "      <td>345614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                area   gss_code 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "1      City of London  E09000001         91448.98487         82202.77314   \n",
       "2  Barking & Dagenham  E09000002          50460.2266         51085.77983   \n",
       "\n",
       "0 1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "1         79120.70256         77101.20804         84409.14932   \n",
       "2         51268.96956         53133.50526         53042.24852   \n",
       "\n",
       "0 1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  ...  \\\n",
       "1         94900.51244         110128.0423         112329.4376  ...   \n",
       "2         53700.34831         52113.12157         52232.19868  ...   \n",
       "\n",
       "0 2022-12-01 00:00:00 2023-01-01 00:00:00 2023-02-01 00:00:00  \\\n",
       "1              975240              963094              869039   \n",
       "2              355596              353429              346193   \n",
       "\n",
       "0 2023-03-01 00:00:00 2023-04-01 00:00:00 2023-05-01 00:00:00  \\\n",
       "1              930986              903718              958418   \n",
       "2              345288              348254              349590   \n",
       "\n",
       "0 2023-06-01 00:00:00 2023-07-01 00:00:00 2023-08-01 00:00:00  \\\n",
       "1              951649              931176              861107   \n",
       "2              346099              343430              344171   \n",
       "\n",
       "0 2023-09-01 00:00:00  \n",
       "1              807475  \n",
       "2              345614  \n",
       "\n",
       "[2 rows x 347 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP: Rename first & second cols. Note that renaming NaT col need to use pd.NaT (without quotes)\n",
    "#AP: internet search told me that second col is GSS codes of the boroughs\n",
    "properties_2_3 = properties_2_2.rename({'Unnamed: 0':'area', pd.NaT:'gss_code'}, axis=1)\n",
    "properties_2_3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_2_4 = properties_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [],
   "source": [
    "#Gonna deal with the missing values here, I feel simpler to do now than after melting\n",
    "#Find what extra areas are in the DF in addition to the 32 boroughs + City of London & make a list of them\n",
    "#boroughs copied from internet\n",
    "boroughs_list = ['City of London', 'Camden', 'Greenwich', 'Hackney', 'Hammersmith & Fulham', 'Islington', 'Kensington & Chelsea', 'Lambeth', 'Lewisham', 'Southwark', 'Tower Hamlets', 'Wandsworth', 'Westminster', 'Barking & Dagenham', 'Barnet', 'Bexley', 'Brent', 'Bromley', 'Croydon', 'Ealing', 'Enfield', 'Haringey', 'Harrow', 'Havering', 'Hillingdon', 'Hounslow', 'Kingston upon Thames', 'Merton', 'Newham', 'Redbridge', 'Richmond upon Thames', 'Sutton', 'Waltham Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique areas:\n",
      " ['City of London' 'Barking & Dagenham' 'Barnet' 'Bexley' 'Brent' 'Bromley'\n",
      " 'Camden' 'Croydon' 'Ealing' 'Enfield' 'Greenwich' 'Hackney'\n",
      " 'Hammersmith & Fulham' 'Haringey' 'Harrow' 'Havering' 'Hillingdon'\n",
      " 'Hounslow' 'Islington' 'Kensington & Chelsea' 'Kingston upon Thames'\n",
      " 'Lambeth' 'Lewisham' 'Merton' 'Newham' 'Redbridge' 'Richmond upon Thames'\n",
      " 'Southwark' 'Sutton' 'Tower Hamlets' 'Waltham Forest' 'Wandsworth'\n",
      " 'Westminster' 'Unnamed: 34' 'Inner London' 'Outer London' 'Unnamed: 37'\n",
      " 'NORTH EAST' 'NORTH WEST' 'YORKS & THE HUMBER' 'EAST MIDLANDS'\n",
      " 'WEST MIDLANDS' 'EAST OF ENGLAND' 'LONDON' 'SOUTH EAST' 'SOUTH WEST'\n",
      " 'Unnamed: 47' 'England']\n",
      "-------------------- \n",
      "unique count: 48\n",
      "\n",
      "Excess elements of DF columns vs boroughs_list:\n",
      "['EAST MIDLANDS' 'EAST OF ENGLAND' 'England' 'Inner London' 'LONDON'\n",
      " 'NORTH EAST' 'NORTH WEST' 'Outer London' 'SOUTH EAST' 'SOUTH WEST'\n",
      " 'Unnamed: 34' 'Unnamed: 37' 'Unnamed: 47' 'WEST MIDLANDS'\n",
      " 'YORKS & THE HUMBER']\n",
      "Len of boroughs list:  33\n",
      "Len of unique_areas list:  48\n",
      "Len of excess list:  15\n",
      "Diff in len's:  33\n",
      "Diff = 33?: Yes\n"
     ]
    }
   ],
   "source": [
    "print('unique areas:\\n',properties_2_4['area'].unique())\n",
    "print('-'*20, '\\nunique count:', len(properties_2_4['area'].unique()))\n",
    "unique_areas = properties_2_4['area'].unique()\n",
    "print('\\nExcess elements of DF columns vs boroughs_list:')\n",
    "print(np.setdiff1d(list(unique_areas), boroughs_list))\n",
    "excess_areas = list(np.setdiff1d(list(unique_areas), boroughs_list))\n",
    "print('Len of boroughs list: ', len(boroughs_list))\n",
    "print('Len of unique_areas list: ',len(unique_areas))\n",
    "print('Len of excess list: ',len(excess_areas))\n",
    "diff_unique_excess = len(unique_areas) - len(excess_areas)\n",
    "print(\"Diff in len's: \", diff_unique_excess)\n",
    "print('Diff = 33?:', 'Yes' if diff_unique_excess == 33 else 'No, check list contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         area   gss_code 1995-01-01 00:00:00  \\\n",
      "area                                                            \n",
      "City of London  City of London  E09000001         91448.98487   \n",
      "\n",
      "0              1995-02-01 00:00:00 1995-03-01 00:00:00 1995-04-01 00:00:00  \\\n",
      "area                                                                         \n",
      "City of London         82202.77314         79120.70256         77101.20804   \n",
      "\n",
      "0              1995-05-01 00:00:00 1995-06-01 00:00:00 1995-07-01 00:00:00  \\\n",
      "area                                                                         \n",
      "City of London         84409.14932         94900.51244         110128.0423   \n",
      "\n",
      "0              1995-08-01 00:00:00  ... 2022-12-01 00:00:00  \\\n",
      "area                                ...                       \n",
      "City of London         112329.4376  ...              975240   \n",
      "\n",
      "0              2023-01-01 00:00:00 2023-02-01 00:00:00 2023-03-01 00:00:00  \\\n",
      "area                                                                         \n",
      "City of London              963094              869039              930986   \n",
      "\n",
      "0              2023-04-01 00:00:00 2023-05-01 00:00:00 2023-06-01 00:00:00  \\\n",
      "area                                                                         \n",
      "City of London              903718              958418              951649   \n",
      "\n",
      "0              2023-07-01 00:00:00 2023-08-01 00:00:00 2023-09-01 00:00:00  \n",
      "area                                                                        \n",
      "City of London              931176              861107              807475  \n",
      "\n",
      "[1 rows x 347 columns]\n",
      "(48, 347)\n"
     ]
    }
   ],
   "source": [
    "#AP: set 'area' col as index so I can drop desired rows, keeping the 'area' col and resetting the index after\n",
    "#AP: Better way to do this?\n",
    "properties_2_4.index =properties_2_4['area']\n",
    "print(properties_2_4.head(1)) #visual check I set index correctly\n",
    "print(properties_2_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: edited out inplace=True and assigned code to a var\n",
    "properties_2_4_1 = properties_2_4.drop(index=excess_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (33, 347)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>gss_code</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-12-01 00:00:00</th>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <th>2023-02-01 00:00:00</th>\n",
       "      <th>2023-03-01 00:00:00</th>\n",
       "      <th>2023-04-01 00:00:00</th>\n",
       "      <th>2023-05-01 00:00:00</th>\n",
       "      <th>2023-06-01 00:00:00</th>\n",
       "      <th>2023-07-01 00:00:00</th>\n",
       "      <th>2023-08-01 00:00:00</th>\n",
       "      <th>2023-09-01 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>...</td>\n",
       "      <td>975240</td>\n",
       "      <td>963094</td>\n",
       "      <td>869039</td>\n",
       "      <td>930986</td>\n",
       "      <td>903718</td>\n",
       "      <td>958418</td>\n",
       "      <td>951649</td>\n",
       "      <td>931176</td>\n",
       "      <td>861107</td>\n",
       "      <td>807475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>...</td>\n",
       "      <td>355596</td>\n",
       "      <td>353429</td>\n",
       "      <td>346193</td>\n",
       "      <td>345288</td>\n",
       "      <td>348254</td>\n",
       "      <td>349590</td>\n",
       "      <td>346099</td>\n",
       "      <td>343430</td>\n",
       "      <td>344171</td>\n",
       "      <td>345614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                 area   gss_code 1995-01-01 00:00:00  \\\n",
       "area                                                                    \n",
       "City of London          City of London  E09000001         91448.98487   \n",
       "Barking & Dagenham  Barking & Dagenham  E09000002          50460.2266   \n",
       "\n",
       "0                  1995-02-01 00:00:00 1995-03-01 00:00:00  \\\n",
       "area                                                         \n",
       "City of London             82202.77314         79120.70256   \n",
       "Barking & Dagenham         51085.77983         51268.96956   \n",
       "\n",
       "0                  1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "area                                                         \n",
       "City of London             77101.20804         84409.14932   \n",
       "Barking & Dagenham         53133.50526         53042.24852   \n",
       "\n",
       "0                  1995-06-01 00:00:00 1995-07-01 00:00:00  \\\n",
       "area                                                         \n",
       "City of London             94900.51244         110128.0423   \n",
       "Barking & Dagenham         53700.34831         52113.12157   \n",
       "\n",
       "0                  1995-08-01 00:00:00  ... 2022-12-01 00:00:00  \\\n",
       "area                                    ...                       \n",
       "City of London             112329.4376  ...              975240   \n",
       "Barking & Dagenham         52232.19868  ...              355596   \n",
       "\n",
       "0                  2023-01-01 00:00:00 2023-02-01 00:00:00  \\\n",
       "area                                                         \n",
       "City of London                  963094              869039   \n",
       "Barking & Dagenham              353429              346193   \n",
       "\n",
       "0                  2023-03-01 00:00:00 2023-04-01 00:00:00  \\\n",
       "area                                                         \n",
       "City of London                  930986              903718   \n",
       "Barking & Dagenham              345288              348254   \n",
       "\n",
       "0                  2023-05-01 00:00:00 2023-06-01 00:00:00  \\\n",
       "area                                                         \n",
       "City of London                  958418              951649   \n",
       "Barking & Dagenham              349590              346099   \n",
       "\n",
       "0                  2023-07-01 00:00:00 2023-08-01 00:00:00 2023-09-01 00:00:00  \n",
       "area                                                                            \n",
       "City of London                  931176              861107              807475  \n",
       "Barking & Dagenham              343430              344171              345614  \n",
       "\n",
       "[2 rows x 347 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP: checking out df, making sure I removed correct areas and kept the london boroughs\n",
    "print('shape: ',properties_2_4_1.shape)\n",
    "properties_2_4_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: Reseting the index to zero-indexing, don't feel need to keep original df intact and drop=True since col already exists\n",
    "properties_2_4_1.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "area                   0\n",
       "gss_code               0\n",
       "1995-01-01 00:00:00    0\n",
       "1995-02-01 00:00:00    0\n",
       "1995-03-01 00:00:00    0\n",
       "                      ..\n",
       "2023-05-01 00:00:00    0\n",
       "2023-06-01 00:00:00    0\n",
       "2023-07-01 00:00:00    0\n",
       "2023-08-01 00:00:00    0\n",
       "2023-09-01 00:00:00    0\n",
       "Length: 347, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP: Confirming no nulls\n",
    "properties_2_4_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match!\n"
     ]
    }
   ],
   "source": [
    "#AP: comparing list of the areas in DF to the boroughs list\n",
    "prop_areas_list = sorted(list(properties_2_4_1['area']))\n",
    "if prop_areas_list == sorted(boroughs_list):\n",
    "    print('match!')\n",
    "else:\n",
    "    print('Not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: commenting this out, I made more concise code above\n",
    "#unique_areas2 = list(properties_2_4['area'].unique())\n",
    "#if sorted(unique_areas2) == sorted(boroughs_list):\n",
    "#    print('1-to-1 Match, dropped rows correctly')\n",
    "#elif len(unique_areas2) == len(boroughs_list):\n",
    "#    print('len match, not 1-to-1')\n",
    "#else:\n",
    "#    print('smthn needs fixin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Commenting out, reset_index above (and had assigned different var)\n",
    "#AP: Reset the index to zero-indexing after I drop desired rows\n",
    "#properties_2_4.reset_index(drop=True, inplace=True)\n",
    "#properties_2_4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>gss_code</th>\n",
       "      <th>date</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.51832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.09036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.56698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>Sutton</td>\n",
       "      <td>E09000029</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>437958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>E09000030</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>509454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>E09000031</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>510471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>637929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>E09000033</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>967277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11385 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     area   gss_code       date    avg_price\n",
       "0          City of London  E09000001 1995-01-01  91448.98487\n",
       "1      Barking & Dagenham  E09000002 1995-01-01   50460.2266\n",
       "2                  Barnet  E09000003 1995-01-01  93284.51832\n",
       "3                  Bexley  E09000004 1995-01-01  64958.09036\n",
       "4                   Brent  E09000005 1995-01-01  71306.56698\n",
       "...                   ...        ...        ...          ...\n",
       "11380              Sutton  E09000029 2023-09-01       437958\n",
       "11381       Tower Hamlets  E09000030 2023-09-01       509454\n",
       "11382      Waltham Forest  E09000031 2023-09-01       510471\n",
       "11383          Wandsworth  E09000032 2023-09-01       637929\n",
       "11384         Westminster  E09000033 2023-09-01       967277\n",
       "\n",
       "[11385 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP: Changed vars from properties_2_3 & properties_2_4 to properties_2_4_1 & properties_2_4_2, resepectively\n",
    "#AP:Note to self: purpose of melting DF (in this case at least) is to reduce # of cols and so each row is truly a SINGLE observation\n",
    "properties_2_4_2 = properties_2_4_1.melt(id_vars=['area', 'gss_code'], var_name='date', value_name='avg_price')\n",
    "properties_2_4_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                 object\n",
       "gss_code             object\n",
       "date         datetime64[ns]\n",
       "avg_price            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties_2_4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AP: Note to self, alt way is to use pd.to_numeric(...)\n",
    "#AP: Changed properties_2_4 & properties_2_4_1 to properties_2_4_2, don't feel need to assign new var for changing dtype\n",
    "properties_2_4_2 = properties_2_4_2.astype(dtype= {'avg_price': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                 object\n",
       "gss_code             object\n",
       "date         datetime64[ns]\n",
       "avg_price           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changed properties_2_4_1 to properties_2_4_2\n",
    "properties_2_4_2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_2_5 = properties_2_4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#how many null values in each col\n",
    "print('nulls:\\n',properties_2_5.isna().sum())\n",
    "print('-'*20,'\\nnon-null counts:\\n', properties_2_5.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropped rows of non-borough areas and rows of 100% missing data before melting in step 2.4\n",
    "\n",
    "#drop the excess areas from properties_2_5 DF\n",
    "#properties_2_5_1 = properties_2_5[properties_2_5['area'].isin(excess_areas) == True]\n",
    "#print('excess_areas list:\\n',excess_areas,'\\n')\n",
    "#print(list(properties_2_5_1['area'].unique()))\n",
    "#list( properties_2_5_1['area'].unique()) == excess_areas\n",
    "#print('null count:\\n', properties_2_5.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [],
   "source": [
    "properties_2_6 = properties_2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checking for null's since I've been getting errors\n",
    "properties_2_6.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rand_borough = str(rand.choice(boroughs_list))\n",
    "print(f\"\\nBorough: {rand_borough}\\n\")\n",
    "properties_2_6_plot = properties_2_6[properties_2_6['area'] == f'{rand_borough}'].plot(kind='line', x='date', y='avg_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": [
    "properties_2_6['year'] = properties_2_6['date'].apply(lambda t: t.year)\n",
    "print(properties_2_6.isna().sum())\n",
    "properties_2_6.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_2_6_grp = properties_2_6.groupby(by=['area', 'year']).mean(numeric_only=True)\n",
    "properties_2_6_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_2_6_grp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_2_6_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Can't figure out how to split boroughs apart in plot\n",
    "properties_2_6_plot2 = properties_2_6_grp.plot(kind='line', x='year', y='avg_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_3 = properties_2_6_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_3_indx = properties_3.set_index('area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_3_indx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": [
    "def create_price_ratio (Borough):\n",
    "    \"\"\"Create a price ratio of average London Borough house price betweeen 1998 & 2018\"\"\"\n",
    "    filt_borough = properties_3_indx.loc[Borough]\n",
    "    filt_1998 = filt_borough[filt_borough['year'] == 1998]\n",
    "    filt_2018 = filt_borough[filt_borough['year'] == 2018]\n",
    "    price_1998 = filt_1998.at[f\"{Borough}\", 'avg_price']\n",
    "    price_2018 = filt_2018.at[f\"{Borough}\", 'avg_price']\n",
    "    return f\"{(price_1998/price_2018):.2%}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Note to self: Why append to list not working??? I want to order from largest to smallest\n",
    "print(\"Price increase % for each London Borough between 1998 & 2018\")\n",
    "change_dict = {}\n",
    "for place in boroughs_list:\n",
    "    change_dict[place] = create_price_ratio(place)\n",
    "print(change_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_df = pd.DataFrame.from_dict(change_dict, orient='index', columns=['%_change'])\n",
    "change_df.sort_values('%_change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_df_bar = change_df.reset_index()\n",
    "change_df_bar.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_df_bar.rename(columns={'index':'Borough'}, inplace=True)\n",
    "change_df_bar.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_df_bar.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(kind='bar', data=change_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "## I can conclude that housing prices in London need to calm down. Hackney has the lowest rate of price increase, Hounslow has the highest price increase rate. In the end it woould be easier to group boroughs by ranges of price increase, choose the range you're most comfortable with then compare boroughs using other factors to decide where to live.\n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
