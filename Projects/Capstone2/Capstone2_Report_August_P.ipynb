{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center>Predicting Asthma Diagnosis As A Screening Tool</center></h1>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<center>Link to GitHub Repository<center>](https://github.com/August-JF-Perez/AugustP_Springboard/tree/main/Projects/Capstone2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This project aims to build a predictive model in order to screen whether a patient would be diagnosed with asthma.\n",
    "- The real-world application would be for doctors to more easily determine which patients to focus on, for the more efficient allocation of resources in an already strained healthcare system.\n",
    "- The final model was trained with 26 features/variables for each patient that encompass categories of demographic details, lifestyle factors, environmental and allergy factors, medical history, clinical measurements, symptoms, and including diagnosis indicator.\n",
    "\n",
    "- The final goal is to build a classification model with a focus on maximizing the recall score (sensitivity) to decrease false negatives.\n",
    "\n",
    "\n",
    "Asthma Information from The Mayo Clinic: https://www.mayoclinic.org/diseases-conditions/asthma/symptoms-causes/syc-20369653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in the models explored was \"Asthma Disease Dataset\" from Kaggle\n",
    "\n",
    "[Link to Kaggle Dataset](https://www.kaggle.com/datasets/rabieelkharoua/asthma-disease-dataset?resource=download)\n",
    "\n",
    "Below is a snapshot of the raw data arranged in a dataframe after importing.\n",
    "\n",
    "![original_data_df](images/original_data_dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset has 2392 entries and 29 columns. \n",
    "\n",
    "To ensure clean data prior modeling, unnecessary features were removed (PatientID & DoctorInCharge) as they did not provide information useful for predicting diagnosis.\n",
    "\n",
    "Cleaning:\n",
    "- The data was checked for null values, outliers, value consistency within each feature, and detectable irregularities. No occurences requiring in-depth cleaning were found.\n",
    "\n",
    "Preprocessing:\n",
    "- Categorical features were confirmed to be or converted to indicators of 0 or 1 (dummy variable conversion)\n",
    "- Addition of additional features that would combine features within the same groups to give the magnitude of each feature group was included in the dataset with the goal of indicating that with compunding factors, the chance of asthma diagnosis would increase.\n",
    "- Standardize the magnitude of numeric features to have ranges from 0 to 1 (0 representing the minimum value of the feature, and 1 representing the maximum)\n",
    "- Resampling was performed to address the class imbalance of Non-Diagnosed vs Diagnosed for asthma\n",
    "    - Oversampling performed with replacement to achieve equal count of Diagnosis=0 & Diagnosis=1\n",
    "    - This was not performed on test/validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a snapshot of the cleaned & preprocessed dataset.\n",
    "\n",
    "![clean_df](images/clean_dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Hightlights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Observations**\n",
    "\n",
    "- Continuous columns had relatively flat distributions for all data and when filtered for Diagnosis=0\n",
    "- Continuous columns had multiple different distributions when filtered for Diagnosis=1\n",
    "    - For each feature, there were peaks and valleys shown in the histogram but no peak was tall enough to make the value of the feature jump out as significant or shown to be deterministic for asthma\n",
    "- Categorical columns had very similar distributions when comparing Diagnosis= 0 and 1\n",
    "    - Suggesting that even if one class in the category was in majority, it did not serve as a good indicator by itself if the patient would get diagnosed with asthma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data (Unfiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dist_all](images/distributions_alldata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Fairly flat distributions for numeric variables.**\n",
    "    - bmi, lungfunctionfev1, lungfunctionfvc\n",
    "    - Discrete\n",
    "        - age, ethnicity, educationlevel, physicalactivity, dietquality, sleepquality, pollutionexposure, pollenexposure, dustexposure\n",
    "- **The ratios within the categorical variables seem to reflect ratios expected in the real population.**\n",
    "    - Binary\n",
    "        - gender, smoking, petallergy, familyhistoryasthma, historyofallergies, eczema, hayfever, gastroesophagealreflux, wheezing, shortnessofbreath, chesttightness, coughing, nighttimesymptoms, exerciseinduced, diagnosis (the target variable)\n",
    "    - Ordinal\n",
    "        - age, educationlevel, physicalactivity, dietquality, sleepquality, pollutionexposure, pollenexposure, dustexposure\n",
    "    - Nominal\n",
    "        - ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dist_all](images/distributions_diag_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Near to the same distributions as the unfiltered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dist_all](images/distributions_diag_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numerical variables seemingly have more varied distributions.\n",
    "    - Likely due to about 5% of the total data has Diagnosis = 1.\n",
    "    - pollutionexposure almost a bimodal distribution but not a strong enough case to be confidently classified as such.\n",
    "- Categorical variables have extremely similar ratios to the unfiltered and Diagnosis=0 distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions Between Features\n",
    "\n",
    "Target feature of the dataset: Diagnosis\n",
    "\n",
    "Correlation Heatmap:\n",
    "\n",
    "![corr_heatmap](images/corr_heatmap.png)\n",
    "\n",
    "\n",
    "- Correlation between two features\n",
    " - Highest\n",
    "     - 0.064841 between BMI & DustExposure\n",
    " - Lowest\n",
    "     - -0.059298 between Wheezing & Hayfever\n",
    "\n",
    "- Correlation between the target (diagnosis) & a feature\n",
    "    - Highest\n",
    "        - 0.053956 for ExerciseInduced\n",
    "    - Lowest\n",
    "        - -0.039278 for Chesttightness\n",
    "\n",
    "These correlation correficients indicate there is barely any relationship between features and a relationship between a single feature and Diagnosis. With a correlation of 1 or -1 being a perfect linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/count.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced vs Imbalanced Dataset**\n",
    "\n",
    "- The dataset suffered a class imbalance between Diagnosis=0 (Non-Diagnosed for asthma) & Diagnosis=1 (Diagnosed for asthma).\n",
    "- This implies that  two-class ML modeling may suffer from imbalance in the dataset.\n",
    "- Observations where Diagnosis=1 account for 5.18% of all the data.\n",
    "\n",
    "- This imbalance was addressed as noted in the Data Cleaning & Preprocessing section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methodology**\n",
    "- Choose multiple classification models in the SciKit Learn library that could be reasonably applied to this two-class prediction problem\n",
    "- Fit on data that has been balanced between classes and test/validate on data that did not recieve artifical class balancing\n",
    "- Return scores and model metrics with a **focus on recall (for Diagnosis = 1)**\n",
    "- Choose a best 2 models and perform hyperparameter tuning\n",
    "- Choose best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Random Guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The baseline for which to compare classification models to was created using SciKit Learn's DummyClassifier() function to **simulate random guessing**.\n",
    "    - Applying a Grid Search, the dummy classifier hyperparameter 'strategy' was set to the value 'uniform'\n",
    "- Continuiing the focus on maximizing the recall score, **randomly guessing gave a recall of 37.9%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6 classification models were trained and scored based on their predictions\n",
    "- Some values for model hyperparameters were changed based on applicability to the problem the model was applied to.\n",
    "- The 2 best models then underwent hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and their classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n",
       "<!-- To left-align the classification report tables -->\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>\n",
    "<!-- To left-align the classification report tables -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Decision Tree\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| 0            |        0.94 |     0.95 |       0.95 |     565   |\n",
    "| 1            |        0.03 |     0.03 |       0.03 |      33   |\n",
    "| accuracy     |        0.9  |     0.9  |       0.9  |       0.9 |\n",
    "| macro avg    |        0.49 |     0.49 |       0.49 |     598   |\n",
    "| weighted avg |        0.89 |     0.9  |       0.89 |     598   |\n",
    "\n",
    "\n",
    "Decision Tree:\n",
    "\n",
    "    - Accuracy: 91%\n",
    "    - Recall: 3%\n",
    "    - High scores for diagnosis=0, low scores for diagnosis=1\n",
    "    - Worse recall than dummy classifier\n",
    "\n",
    "### Model 2: Random Forest\n",
    "\n",
    "Classification Report:\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| 0            |        0.94 |     0.95 |       0.95 |     565   |\n",
    "| 1            |        0.03 |     0.03 |       0.03 |      33   |\n",
    "| accuracy     |        0.9  |     0.9  |       0.9  |       0.9 |\n",
    "| macro avg    |        0.49 |     0.49 |       0.49 |     598   |\n",
    "| weighted avg |        0.89 |     0.9  |       0.89 |     598   |\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "    - Accuracy: 94%\n",
    "    - Recall: 0%\n",
    "    - Worse recall than dummy classifier\n",
    "\n",
    "Performed well for diagnosis=0, extremely porrly for predicting diagnosis=1\n",
    "\n",
    "### Model 3: KNN\n",
    "\n",
    "Classification Report:\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| 0            |        0.94 |     0.84 |       0.89 |     565   |\n",
    "| 1            |        0.04 |     0.12 |       0.06 |      33   |\n",
    "| accuracy     |        0.8  |     0.8  |       0.8  |       0.8 |\n",
    "| macro avg    |        0.49 |     0.48 |       0.48 |     598   |\n",
    "| weighted avg |        0.89 |     0.8  |       0.85 |     598   |\n",
    "\n",
    "KNN:\n",
    "\n",
    "    - Accuracy: 80%\n",
    "    - Recall (diag=1): 12%\n",
    "    - Worse recall than dummy classifier\n",
    "\n",
    "KNN did well predicting diagnosis=0, slightly better than previous models but still poorly in predicting diagnosis=1\n",
    "\n",
    "### Model 4: Logistic Regression\n",
    "\n",
    "Classification Report:\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| 0            |        0.95 |     0.59 |       0.73 |    565    |\n",
    "| 1            |        0.06 |     0.45 |       0.11 |     33    |\n",
    "| accuracy     |        0.58 |     0.58 |       0.58 |      0.58 |\n",
    "| macro avg    |        0.5  |     0.52 |       0.42 |    598    |\n",
    "| weighted avg |        0.9  |     0.58 |       0.69 |    598    |\n",
    "\n",
    "Logistic Regression:\n",
    "\n",
    "    - Accuracy: 58%\n",
    "    - Recall: 45%\n",
    "    - Improved recall over dummy classifier\n",
    "\n",
    "Low accuracy but much higher recall vs other models.\n",
    "\n",
    "I theorize this is because the grouping of the data points makes it difficult to make a decision plane such that the model will get about half predictions correct\n",
    "\n",
    "\n",
    "### Model 5: Gradient Boosting\n",
    "    Using decision trees\n",
    "\n",
    "Classification Report:\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| 0            |        0.94 |     0.92 |       0.93 |    565    |\n",
    "| 1            |        0.04 |     0.06 |       0.05 |     33    |\n",
    "| accuracy     |        0.88 |     0.88 |       0.88 |      0.88 |\n",
    "| macro avg    |        0.49 |     0.49 |       0.49 |    598    |\n",
    "| weighted avg |        0.89 |     0.88 |       0.89 |    598    |\n",
    "\n",
    "Gradient Boosting:\n",
    "\n",
    "    - Accuracy: 88%\n",
    "    - Recall: 6%\n",
    "    - Worse recall than dummy classifier\n",
    "\n",
    "Accuracy lower than all models except Logistic Regression (at 58%). Recall (sensitivity) is only better than the tree & forest models.\n",
    "\n",
    "\n",
    "### Model 6: AdaBoost classifier\n",
    "    Using Logistic Regression since that has given the best recall so far\n",
    "\n",
    "Classification Report:\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| 0            |        0.95 |     0.59 |       0.73 |    565    |\n",
    "| 1            |        0.06 |     0.45 |       0.11 |     33    |\n",
    "| accuracy     |        0.58 |     0.58 |       0.58 |      0.58 |\n",
    "| macro avg    |        0.5  |     0.52 |       0.42 |    598    |\n",
    "| weighted avg |        0.9  |     0.58 |       0.69 |    598    |\n",
    "\n",
    "AdaBoost Classifier:\n",
    "\n",
    "    - Accuracy: 58%\n",
    "    - Recall: 45%\n",
    "\n",
    "Almost exact same results as Logistic Regression by itself. Changing weights does not seem to have an effect using default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrixes\n",
    "\n",
    "Confusion Matrixes shown for models that were selected for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![knn_confusion_matrix](images/knn_confusion_matrix.png)\n",
    "![logreg_confusion_matrix](images/logreg_confusion_matrix.png)\n",
    "![ada_confusion_matrix](images/ada_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Top 3 Models\n",
    "The 3 models with the highest recall for Diagnosis=1 were KNN, Logistic Regression, & AdaBoost(LogisticRegression)\n",
    "\n",
    "- KNN recall: 12%\n",
    "- Logistic Regression recall: 45%\n",
    "- AdaBoost classifier recall: 45%\n",
    "\n",
    "Note: KNN inclusion explained in \"Hyperparameter Tuning\" section of this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "    Of the models: KNN, Logistic Regression, & AdaBoost(LogisticRegression)\n",
    "\n",
    "A hyperparamter optimization was performed by applying the GridSearch approach to find the best modeling parameters and further improve the prediction recall (for Diagnosis = 1) of the models. The results show marginally slight improvement in the performance for each classifier after hyperparamter tuning.\n",
    "\n",
    "\n",
    "Logistic Regression & AdaBoost(LogisticRegression) had the highest recall for Diagnosis = 1 (about 45% for each) and were chosen for hyperparameter tuning.\n",
    "\n",
    "KNN only had a recall of about 12%. This model underwent hyperparameter tuning as a means of becoming more familiar with the tools utilized in this project.\n",
    "    \n",
    "    The results of tuning KNN are not shown in this report as they do not improve upon the original model or result in metrics better than Logistic Regression or AdaBoost. This is noted within this report as an indicator for when reviewing the project Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters:\n",
    " - 'class_weight': 'balanced'\n",
    " - 'max_iter': 500\n",
    " - 'random_state': 9\n",
    " - 'solver': 'liblinear'\n",
    "\n",
    "Best recall score: 43%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters:\n",
    "- 'estimator': LogisticRegression(\n",
    "    - class_weight='balanced'\n",
    "    - max_iter=500\n",
    "    - solver='liblinear')\n",
    "- 'learning_rate': 0.1\n",
    "\n",
    "Best recall score: 46%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost saw a 1% improvement in recall while the tuned Logistic Regression model saw a decrease in recall versus the default model.\n",
    "\n",
    "AdaBoost Recall Scores:\n",
    "- Original model: 45%\n",
    "- Tuned model: 46%\n",
    "\n",
    "Logistic Regression Recall Scores:\n",
    "- Original model: 45%\n",
    "- Tuned model: 43%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Best & Final Model\n",
    "\n",
    "AdaBoost Classifier\n",
    "- 'estimator': LogisticRegression(\n",
    "    - class_weight='balanced'\n",
    "    - max_iter=500\n",
    "    - solver='liblinear')\n",
    "- 'learning_rate': 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The goal of this project was to build a classification prediction model as a screening for whether or not a paitent would get diagnosed with asthma if tested using laboratory tests or professional medical examination.\n",
    "    - The final use of the model would be for medical professionals (doctors, RN's, etc.) to more easily prioritize resources towards patients with higher chance of having asthma.\n",
    "        - As opposed to attempting to keep track of every single patient or waiting until symptoms got worsse to fully investigate.\n",
    "    - The prediction would be based on multiple categories of variables such as family history, environmental factors, and any current symptoms.\n",
    "    - The model was focused on maximizing sensitivity as being more accurate in predicting true positives is more beneficial than reducing false positives.\n",
    "        - A false positive for asthma in a screening test (which would result in follow-up examinations and tests) is much less harmful to the patient than a false positive with another disease such as cancer.\n",
    "            - Especially the mental burden on the patient and the higher cost & time requirements of tests for most other diseases.\n",
    "- The methodology applied to the prediction of asthma diagnosis and the maximizing of sensitivity was that of exploring the dataset with statistical and plotting methods, applying multiple binary classification models, tuning of hyperparameters of the best 2 models, then selecting the best of the tuned models.\n",
    "- The overall recall (sensitivity) for correctly predicting a true diagnosis of asthma was fairly low (at 46% recall).\n",
    "    - While diagnostic screening tests can have very low sensitivities (when favoring specificity), any test that aims to minimize false negatives requires a high sensitivity (usually > 80%)\n",
    "- The best model found was the AdaBoost classifier using Logistic Regression as it's estimator.\n",
    "    - The Logistic Regression model alone had similar performance but did not see improvement after hyperparameter tuning.\n",
    "- For real world application, I would recommend against using the model in its current state as a screening test for asthma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Limiting factors to model efficacy were:**\n",
    "\n",
    "- Low count of Diagnosis=1 samples (only about 5% of the original dataset)\n",
    "- The variables chosen in the study could each have extremely weak correlation to asthma diagnosis\n",
    "- Variables not collected in the study could have greater correlation to asthma diagnosis\n",
    "- The sample recored in the dataset does not truly reflect the population (in such a way that bootstrapping does not fully address the issue)\n",
    "- Faulty sample collection or incorrect data handling of the dataset prior to being made available\n",
    "    - This is suspected as the ratios of classes for common symptoms of asthma do not appear to change significantly from Diagnosis=0 to Diagnosis=1\n",
    "        - Common symptoms: Shortness of breath, Chest tightness or pain, Wheezing when exhaling, which is a common sign of asthma in children, Trouble sleeping caused by previously listed symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements to the project would include:\n",
    "\n",
    "- Performing effective feature engineering by learning more about each variable collected in the dataset and gaining a deeper understanding of how they could relate to each other.\n",
    "- Perform feature selection and apply it to the models.\n",
    "    - Gaining a better understanding of how to perform effective feature selection is the hurdle for this improvement.\n",
    "- Gain more data from other studies.\n",
    "    - This would only make the data used for modeling more reflective of the population.\n",
    "    - This might illucidate the potential innacuracies within the original dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
